============================================================================================
                        GUIDA COMPLETA AL TRACCIAMENTO DEL FATTORE K NELLA SVD
                                    SISTEMA DI RACCOMANDAZIONE AFLIX
============================================================================================

INDICE:
1. INTRODUZIONE AL FATTORE K
2. IMPLEMENTAZIONE DEL TRACCIAMENTO
3. ENDPOINTS API DISPONIBILI
4. UTILIZZO PRATICO
5. INTERPRETAZIONE DEI RISULTATI
6. OTTIMIZZAZIONE AVANZATA
7. BEST PRACTICES

============================================================================================
1. INTRODUZIONE AL FATTORE K
============================================================================================

COS'È IL FATTORE K?
Il fattore k rappresenta il numero di componenti (dimensioni latenti) utilizzate nella 
decomposizione SVD (Singular Value Decomposition). È un parametro cruciale che determina:

- QUALITÀ DEL MODELLO: Più componenti = maggiore capacità di catturare pattern complessi
- PERFORMANCE: Meno componenti = calcoli più veloci, meno overfitting
- MEMORY USAGE: k componenti = k × (n_users + n_movies) parametri da memorizzare

FORMULA SVD:
R ≈ U_k × Σ_k × V_k^T

Dove:
- R: Matrice originale utenti×film
- k: Numero di componenti selezionati (fattore k)
- U_k: Primi k fattori latenti degli utenti
- V_k: Primi k fattori latenti dei film

TRADE-OFF FONDAMENTALE:
- k TROPPO BASSO → Underfitting (modello troppo semplice)
- k TROPPO ALTO → Overfitting (memorizza rumore)
- k OTTIMALE → Bilanciamento perfetto bias-varianza

============================================================================================
2. IMPLEMENTAZIONE DEL TRACCIAMENTO
============================================================================================

VARIABILI DI TRACCIAMENTO AGGIUNTE:

```python
class MLRecommendationService:
    def __init__(self):
        # ... altri attributi ...
        
        # Tracciamento fattore k
        self.actual_k_used = 0              # k effettivamente utilizzato
        self.k_history = []                 # Storico valori k testati
        self.variance_per_component = []    # Varianza per ogni componente
        self.optimal_k = None               # k ottimale identificato
        self.k_performance_log = {}         # Log performance per diversi k
```

METODI IMPLEMENTATI:

A) analyze_k_factor():
   - Analisi dettagliata del k attuale
   - Calcolo varianza cumulativa per componente
   - Identificazione elbow point
   - Raccomandazione k ottimale

B) optimize_k_factor(k_range):
   - Test di diversi valori k
   - Valutazione con train/test split
   - Identificazione k con migliore score
   - Logging completo dei risultati

C) get_k_factor_report():
   - Report completo con analisi e raccomandazioni
   - Storico delle ottimizzazioni
   - Avvertimenti e suggerimenti

D) get_model_status() [ESTESO]:
   - Status con informazioni dettagliate su k
   - Efficienza dei componenti
   - Disponibilità ottimizzazioni

============================================================================================
3. ENDPOINTS API DISPONIBILI
============================================================================================

BASE URL: http://localhost:8000/admin/ml/

A) GET /k-factor-analysis
   DESCRIZIONE: Analizza il fattore k attuale
   RISPOSTA: {
       "current_k": 25,
       "requested_k": 50,
       "total_explained_variance": 0.847,
       "variance_per_component": [0.234, 0.187, 0.156, ...],
       "cumulative_variance": [...],
       "elbow_point": 12,
       "recommended_k": 15
   }

B) POST /optimize-k-factor
   DESCRIZIONE: Ottimizza il fattore k testando diversi valori
   BODY: {"k_range": [5, 10, 15, 20, 25, 30]}  # Opzionale
   RISPOSTA: {
       "best_k": 15,
       "current_k": 25,
       "improvement": true,
       "all_results": [
           {"k": 15, "rmse": 0.89, "mae": 0.67, "explained_variance": 0.82, "combined_score": 0.48},
           ...
       ],
       "recommendation": "Use k=15 for optimal performance"
   }

C) GET /k-factor-report
   DESCRIZIONE: Report completo sul fattore k
   RISPOSTA: {
       "current_status": {...},
       "k_analysis": {...},
       "k_history": [...],
       "performance_log": {...},
       "recommendations": [
           {"type": "optimization", "message": "Consider running k optimization..."},
           ...
       ]
   }

D) GET /model-status-extended
   DESCRIZIONE: Status esteso del modello con dettagli k
   RISPOSTA: {
       "is_trained": true,
       "actual_k_used": 25,
       "requested_k": 50,
       "k_efficiency": 0.0339,
       "explained_variance": 0.847,
       "variance_per_component": [...],
       "k_optimization_available": true
   }

E) POST /update-k-components/{new_k}
   DESCRIZIONE: Aggiorna k e riaddestra il modello
   PARAMETRI: new_k (path parameter)
   RISPOSTA: {
       "update_successful": true,
       "old_k": 25,
       "new_k": 15,
       "old_variance": 0.847,
       "new_variance": 0.823,
       "improvement": false,
       "training_stats": {...}
   }

============================================================================================
4. UTILIZZO PRATICO
============================================================================================

WORKFLOW TIPICO DI OTTIMIZZAZIONE:

1. CONTROLLO STATUS INIZIALE:
   ```python
   import requests
   
   response = requests.get("http://localhost:8000/admin/ml/model-status-extended")
   status = response.json()
   
   print(f"K attuale: {status['actual_k_used']}")
   print(f"Varianza spiegata: {status['explained_variance']:.1%}")
   print(f"Efficienza K: {status['k_efficiency']:.4f}")
   ```

2. ANALISI DETTAGLIATA:
   ```python
   response = requests.get("http://localhost:8000/admin/ml/k-factor-analysis")
   analysis = response.json()
   
   print(f"K raccomandato: {analysis['recommended_k']}")
   print(f"Elbow point: {analysis['elbow_point']}")
   ```

3. OTTIMIZZAZIONE:
   ```python
   # Test range intorno al valore raccomandato
   k_range = list(range(5, 31, 5))  # [5, 10, 15, 20, 25, 30]
   
   response = requests.post("http://localhost:8000/admin/ml/optimize-k-factor",
                           json={"k_range": k_range})
   optimization = response.json()
   
   best_k = optimization['best_k']
   print(f"K ottimale: {best_k}")
   ```

4. APPLICAZIONE RISULTATO:
   ```python
   if optimization['improvement']:
       response = requests.post(f"http://localhost:8000/admin/ml/update-k-components/{best_k}")
       result = response.json()
       print(f"Aggiornamento: {'Successo' if result['update_successful'] else 'Fallito'}")
   ```

============================================================================================
5. INTERPRETAZIONE DEI RISULTATI
============================================================================================

METRICHE CHIAVE:

A) EXPLAINED VARIANCE RATIO:
   - Range: [0, 1]
   - 0.5-0.7: Buono
   - 0.7-0.9: Eccellente
   - >0.9: Possibile overfitting

B) K EFFICIENCY:
   - Formula: explained_variance / k_used
   - Maggiore = migliore efficienza dei componenti
   - Aiuta a identificare k con miglior rapporto qualità/complessità

C) ELBOW POINT:
   - Punto dove l'aggiunta di componenti non migliora significativamente
   - Indica il k ottimale dal punto di vista della varianza spiegata
   - Metodo: trova dove la derivata della varianza cala sotto 10% del massimo

D) COMBINED SCORE (nell'ottimizzazione):
   - Formula: RMSE - (explained_variance × 0.5)
   - Bilancia accuratezza predittiva e capacità di generalizzazione
   - Più basso = migliore

RACCOMANDAZIONI AUTOMATICHE:

1. "Low explained variance" → Aumentare k o migliorare qualità dati
2. "Using much fewer components than requested" → Dataset limitato
3. "High k with excellent variance" → Possibile ottimizzazione per ridurre k

============================================================================================
6. OTTIMIZZAZIONE AVANZATA
============================================================================================

STRATEGIE DI OTTIMIZZAZIONE:

A) GRID SEARCH INTELLIGENTE:
   ```python
   # Prima fase: ricerca grossolana
   coarse_range = list(range(5, 51, 10))  # [5, 15, 25, 35, 45]
   
   # Seconda fase: ricerca fine intorno al migliore
   best_coarse = optimize_k_factor(coarse_range)['best_k']
   fine_range = list(range(max(1, best_coarse-5), best_coarse+6))
   
   final_optimal = optimize_k_factor(fine_range)['best_k']
   ```

B) ADAPTIVE K SELECTION:
   ```python
   def adaptive_k_selection(min_variance_target=0.8):
       analysis = analyze_k_factor()
       
       for item in analysis['cumulative_variance']:
           if item['cumulative_variance'] >= min_variance_target:
               return item['component']
       
       return analysis['recommended_k']
   ```

C) CROSS-VALIDATION K TUNING:
   - L'endpoint optimize_k_factor() usa train/test split
   - Per CV completa, implementare K-fold validation
   - Considerare computational cost vs. accuracy gain

PARAMETRI DI TUNING:

1. TARGET_VARIANCE: 0.8-0.95 (default: 0.95)
2. ELBOW_THRESHOLD: 0.05-0.15 (default: 0.1)
3. COMBINED_SCORE_WEIGHT: 0.3-0.7 (default: 0.5)

============================================================================================
7. BEST PRACTICES
============================================================================================

MONITORAGGIO CONTINUO:

1. CONTROLLA K DOPO OGNI TRAINING:
   - Il k ottimale può cambiare con nuovi dati
   - Dataset più grandi possono supportare k più alti
   - Nuovi pattern possono richiedere più componenti

2. AUTOMATIZZA CONTROLLI:
   ```python
   def auto_k_check():
       status = get_model_status()
       
       if status['k_efficiency'] < 0.02:  # Soglia bassa efficienza
           print("⚠️  Bassa efficienza K - considera ottimizzazione")
           return optimize_k_factor()
       
       if status['explained_variance'] < 0.6:
           print("⚠️  Bassa varianza spiegata - aumenta K")
           
       return None
   ```

3. LOG DELLE PERFORMANCE:
   - Traccia RMSE/MAE nel tempo per diversi k
   - Identifica pattern stagionali nei dati
   - Documenta miglioramenti dopo ottimizzazioni

REGOLE EMPIRICHE:

1. DATASET PICCOLO (< 1000 rating):
   - k consigliato: 5-15
   - Focus su generalizzazione

2. DATASET MEDIO (1000-10000 rating):
   - k consigliato: 15-35
   - Bilanciamento bias-varianza

3. DATASET GRANDE (> 10000 rating):
   - k consigliato: 30-60
   - Può catturare pattern complessi

4. COLD START PROBLEM:
   - Nuovi utenti: riduci k per generalizzazione
   - Nuovi item: aumenta k per catturare diversità

TROUBLESHOOTING COMUNE:

Q: "K ottimale è sempre 1?"
A: Dataset troppo piccolo o troppo rumoroso. Aumenta dati o applica filtri.

Q: "Varianza spiegata sempre bassa?"
A: Possibili cause:
   - Dati troppo sparsi
   - Rating casuali (utenti non consistenti)
   - Bias sistematici nei dati

Q: "Ottimizzazione non trova miglioramenti?"
A: K attuale già vicino all'ottimale. Sistema stabile.

METRICHE DI ALLERTA:

- k_efficiency < 0.02 → Revisionare architettura
- explained_variance < 0.4 → Problemi dati di base
- actual_k_used << requested_k → Dataset limitato

============================================================================================

CONCLUSIONE:
Il tracciamento del fattore k è essenziale per mantenere performance ottimali nel sistema
di raccomandazione. L'implementazione fornisce strumenti completi per monitoraggio,
analisi e ottimizzazione automatica, garantendo che il modello si adatti dinamicamente
ai cambiamenti nei dati e nei pattern di utilizzo.

Utilizzare regolarmente gli endpoint di analisi e ottimizzazione per mantenere il sistema
al picco delle performance e identificare proattivamente problemi di configurazione.

============================================================================================